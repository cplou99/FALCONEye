
<div align="center">
    <img src="FALCONEyeLogo.png" alt="Description" width="150">
</div>

<h1 align="center">FALCONEye: Finding Answers and Localizing Content in ONE-hour-long videos with multi-modal LLMs</h1>

<p align="center" style="display: flex; justify-content: center; gap: 5px; flex-wrap: nowrap; margin: 0;">
    <a href="https://cplou99.github.io/FALCONEye/">
        <img alt="Build" src="http://img.shields.io/badge/Project Page-FALCONEye-blue" style="height: 30px;">
    </a>
    <a href="https://arxiv.org/abs/2503.19850">
        <img alt="Build" src="http://img.shields.io/badge/cs.CV-arXiv-red" style="height: 30px;">
    </a>
</p>
<p align="center" style="display: flex; justify-content: center; gap: 5px; flex-wrap: nowrap; margin: 0;">
    <a href="https://huggingface.co/datasets/cplou99/FALCON-Bench">
        <img alt="Build" src="https://img.shields.io/badge/ðŸ¤— Dataset-FALCON Benchmark-yellow" style="height: 30px;">
    </a>
    <a href="https://github.com/cplou99/FALCONEye">
        <img alt="Build" src="https://img.shields.io/badge/Github-FALCONEye-green" style="height: 30px;">
    </a>
</p>




This repo contains the benchmark presented in the paper "[FALCONEye: Finding Answers and Localizing Content in ONE-hour-long videos with multi-modal LLMs]()".




## ðŸ”” News:
- ðŸ¥³ 3/26/2025: We have released the [FALCON-Bench](https://huggingface.co/datasets/cplou99/FALCON-Bench) and [Paper](https://arxiv.org/abs/2503.19850)! ðŸ”¥
